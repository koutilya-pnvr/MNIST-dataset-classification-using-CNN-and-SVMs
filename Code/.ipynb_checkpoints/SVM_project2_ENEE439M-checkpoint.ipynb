{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data classification using SVMs\n",
    "In this demonstration, I implemented two different SVM classifiers SVC() and LinearSVC() that are based on libsvm and liblinear libraries on MNIST datasets. In addition three different kernels are studied for the SVC() classifier:\n",
    "1. Radial Basis Function (RBF)\n",
    "2. Polynomial\n",
    "3. Linear\n",
    "\n",
    "In the second stage, PCA is applied on the dataset before classifying using LinearSVC() classifier. The effect on the prediction accuracy due to the chosen number of Principal components is also studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import svm,metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.layers import flatten\n",
    "mnist=input_data.read_data_sets(\".\",one_hot=True,reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Retrieve the training and test data\n",
    "trainX, trainY = flatten(mnist.train.images), mnist.train.labels\n",
    "testX, testY            = flatten(mnist.test.images), mnist.test.labels\n",
    "sess=tf.Session()\n",
    "with sess.as_default():\n",
    "    trainX=trainX.eval()\n",
    "    testX=testX.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "label=[]\n",
    "for y in trainY:\n",
    "    label+=list(np.where(y==1)[0])\n",
    "test_label=[]\n",
    "for y in testY:\n",
    "    test_label+=list(np.where(y==1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having preprocessed the data, the choice of kernel is very important for classification purposes. The idea of using kernel is illustrated in the following figure:\n",
    "<img src=\"kernel.png\" width=\"600\" height=\"600\" />\n",
    "A Kernel essentially transforms a linearly non separable data into a higher dimensional feature space where we can find a hyperplane that can linearly separate the datapoints. The three most commonly used kernel functions in training an SVM are as follows:\n",
    "1. Radial Basis Function (RBF):\n",
    "    $$K(x^{(i)},x^{(j)}) = \\phi(x^{(i)})^T.\\phi(x^{(j)}) = e^{-\\gamma||x^{(i)}-x^{(j)}||^2}$$\n",
    "2. Polynomial:\n",
    "    $$K(x^{(i)},x^{(j)}) = (x^{(i)^{T}}.x^{(j)}+c)^d$$\n",
    "3. Linear:\n",
    "    $$K(x^{(i)},x^{(j)}) = x^{(i)^{T}}.x^{(j)}$$\n",
    "\n",
    "The following code sections shows the accuracy and some more important parameters for these three different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Support vectors dimenstions:  (18451, 784)\n",
      "Number of support vectors for each class 0-9:  [1050 1093 1866 2148 1875 2490 1385 1699 2355 2490]\n",
      "Indices of the support vectors:  [   52    82   144 ..., 54969 54973 54992]\n",
      "Accuracy for SVC:  0.9439\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(trainX, label) \n",
    "print(clf)\n",
    "\n",
    "print(\"Support vectors dimenstions: \",clf.support_vectors_.shape)\n",
    "print(\"Number of support vectors for each class 0-9: \",clf.n_support_ )\n",
    "print(\"Indices of the support vectors: \",clf.support_ )\n",
    "\n",
    "accuracy=clf.score(testX,test_label)\n",
    "print(\"Accuracy for SVC: \",accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poly Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Support vectors dimenstions:  (51465, 784)\n",
      "Number of support vectors for each class 0-9:  [4006 5920 5055 5290 5306 4987 4921 5492 5065 5423]\n",
      "Indices of the support vectors:  [   10    48    52 ..., 54973 54990 54992]\n",
      "Accuracy for SVC using poly kernel :  0.5532\n"
     ]
    }
   ],
   "source": [
    "clf_poly = svm.SVC(kernel='poly')\n",
    "clf_poly.fit(trainX, label) \n",
    "print(clf_poly)\n",
    "\n",
    "print(\"Support vectors dimenstions: \",clf_poly.support_vectors_.shape)\n",
    "print(\"Number of support vectors for each class 0-9: \",clf_poly.n_support_ )\n",
    "print(\"Indices of the support vectors: \",clf_poly.support_ )\n",
    "\n",
    "accuracy_poly=clf_poly.score(testX,test_label)\n",
    "print(\"Accuracy for SVC using poly kernel : \",accuracy_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Support vectors dimenstions:  (9620, 784)\n",
      "Number of support vectors for each class 0-9:  [ 524  470 1027 1239  918 1287  647  898 1346 1264]\n",
      "Indices of the support vectors:  [   52   144   192 ..., 54969 54973 54992]\n",
      "Accuracy for SVC using poly kernel :  0.9393\n"
     ]
    }
   ],
   "source": [
    "clf_linK = svm.SVC(kernel='linear')\n",
    "clf_linK.fit(trainX, label) \n",
    "print(clf_linK)\n",
    "\n",
    "print(\"Support vectors dimenstions: \",clf_linK.support_vectors_.shape)\n",
    "print(\"Number of support vectors for each class 0-9: \",clf_linK.n_support_ )\n",
    "print(\"Indices of the support vectors: \",clf_linK.support_ )\n",
    "\n",
    "accuracy_linK=clf_linK.score(testX,test_label)\n",
    "print(\"Accuracy for SVC using poly kernel : \",accuracy_linK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having studied the accuracies of 3 different kernels of SVC(), we see that the best accuracy is for the RBF kernel (94.39%). This is because the RBF kernel projects the data into an infinite dimensional space where finding a linear classifier (hyperplane) becomes much more probable. Also, we dont see much difference in using Linear or RBF Kernels because MNIST has 784 features. Thats huge in itself that one doesn't need to use a kernel function to project into a higher dimensional feature space. The data is almost linearly separable in the 784 dimensional feature space and thus using RBF kernel is computational expensive in this case as the classifier needs to train 2 cofficients \\gamma and C. We can also see that the polynomial kernel  with degree 3 has an accuracy of 55.32% and this can be increased if the degree of the polynomial kernel is increased to say 4 or 5. \n",
    "\n",
    "The following shows the classification report and the confusion matrix for SVC() using a RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.99      0.97       980\n",
      "          1       0.97      0.99      0.98      1135\n",
      "          2       0.94      0.93      0.93      1032\n",
      "          3       0.93      0.94      0.93      1010\n",
      "          4       0.93      0.95      0.94       982\n",
      "          5       0.93      0.91      0.92       892\n",
      "          6       0.95      0.97      0.96       958\n",
      "          7       0.96      0.93      0.94      1028\n",
      "          8       0.94      0.92      0.93       974\n",
      "          9       0.94      0.92      0.93      1009\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 967    0    1    0    0    5    5    1    1    0]\n",
      " [   0 1120    2    3    0    1    3    1    5    0]\n",
      " [   8    1  960    9   11    1   14    8   18    2]\n",
      " [   0    1   16  950    1   17    1    9   11    4]\n",
      " [   1    1    7    0  937    0    8    2    2   24]\n",
      " [   7    5    5   32    7  809   11    2    9    5]\n",
      " [   9    3    4    1    6    9  925    0    1    0]\n",
      " [   2   13   22    5    8    0    0  955    3   20]\n",
      " [   4    7    7   14    8   23   10    6  892    3]\n",
      " [   9    7    0   12   33    5    1   13    5  924]]\n"
     ]
    }
   ],
   "source": [
    "predicted=clf.predict(testX)\n",
    "expected=test_label\n",
    "\n",
    "#clf.get_params(deep=True)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (clf, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The main difference between SVC() and LinearSVC() is that, they use libsvm and liblinear libraries respectively internally. So LinearSVC() has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "Also, in multiclass classification, liblinear does one-vs-rest by default whereas libsvm does one-vs-one. In other words, for a 10 class problem like MNIST, LinearSVC() produces just 10 classifiers whereas SVC() produces 10*(10-1)/2=45 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Accuracy for linear SVM:  0.917\n"
     ]
    }
   ],
   "source": [
    "lin_clf = svm.LinearSVC()\n",
    "print(lin_clf.fit(trainX, label))\n",
    "lin_accuracy=lin_clf.score(testX,test_label)\n",
    "print(\"Accuracy for linear SVM: \",lin_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that the LinearSVC also implements an alternative multi-class strategy, the so-called multi-class SVM formulated by Crammer and Singer, by using the option multi_class='crammer_singer'. This method is consistent, which is not true for one-vs-rest classification. In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less.\n",
    "\n",
    "As similar to previous, the classification report and the confusion matrix is shown below for the LinearSVC() classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96       980\n",
      "          1       0.96      0.98      0.97      1135\n",
      "          2       0.94      0.88      0.91      1032\n",
      "          3       0.89      0.91      0.90      1010\n",
      "          4       0.91      0.93      0.92       982\n",
      "          5       0.89      0.86      0.87       892\n",
      "          6       0.94      0.95      0.94       958\n",
      "          7       0.92      0.92      0.92      1028\n",
      "          8       0.87      0.87      0.87       974\n",
      "          9       0.89      0.89      0.89      1009\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 960    0    1    1    1    4    7    3    2    1]\n",
      " [   0 1115    3    1    0    1    4    1   10    0]\n",
      " [  11    9  911   19   10    4   13   13   39    3]\n",
      " [   4    0   17  920    2   22    5   12   19    9]\n",
      " [   1    4    6    2  914    0    8    3    5   39]\n",
      " [  10    2    1   42   12  764   16    8   29    8]\n",
      " [   8    4    6    2    6   21  908    1    2    0]\n",
      " [   2   10   19    7    8    1    1  943    3   34]\n",
      " [  12   12    7   19   13   34    8   12  844   13]\n",
      " [   7    8    2   15   33   12    0   25   12  895]]\n"
     ]
    }
   ],
   "source": [
    "predicted_lin=lin_clf.predict(testX)\n",
    "\n",
    "#clf.get_params(deep=True)\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (lin_clf, metrics.classification_report(expected, predicted_lin)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted_lin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Summary so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I studied 2 SVM functions in the sklearn library for the MNIST dataset, SVC() and LinearSVC(). The MNIST dataset is as follows:\n",
    "1. Training: 55000 images\n",
    "2. Test    : 10000 images\n",
    "\n",
    "I also studied the SVC_SVM for 3 different kernels: RBF, Poly and Linear. From the above results, we can see that the accuracies for the three versions of SVC_SVM are 94.39%, 55.32% , 93.33% respectively.\n",
    "Also, the accuracy for the LinearSVC is found to be 91.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### PCA on a linearSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracies=list()\n",
    "for k in range(100,500,50):\n",
    "    pca= PCA(n_components=k)\n",
    "    pca.fit(trainX)\n",
    "    train_pca=pca.transform(trainX)\n",
    "    test_pca=pca.transform(testX)\n",
    "    lin_clf1 = svm.LinearSVC()\n",
    "    lin_clf1.fit(train_pca, label)\n",
    "    accuracies.append(lin_clf1.score(test_pca,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE4lzzrkq8UTinHOuSv4/AjYaXq8kjsUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1f20023cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(range(100,500,50)),accuracies)\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"PCA applied on Linear SVM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion: PCA applied on LinearSVC() SVM\n",
    "We can see an overall increasing trend of the accuracy with the number of principal components. The classification accuracy is traded for the improvement in SVM training time for lower dimensional feature space training data. SVM is essentially a convex Quadratic problem the solving time of which is highly dependent on the number of training vectors and number of features in each vector. The main reason for rhis behavior is due to the calculation of Kernel matrix that's happening internally and which is computationally intensive.\n",
    "\n",
    "We can see that the accuracy is not much reduced with reducing the number of principal components (91.8% -> 91.3% from 450 -> 100 PCAs). But instead by doing PCA we will gain lot of advantage on computational time in training the SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
